\documentclass[12pt, a4paper]{article}

% Настройка размера страницы
\usepackage[a4paper,bindingoffset=0.2in,%
            left=1in,right=1in,top=1in,bottom=1in,%
            footskip=.25in]{geometry}

% Настройка шрифтов
\usepackage[russian]{babel}
\usepackage{fontspec}
\setmainfont[
  Ligatures=TeX,
  Extension=.otf,
  BoldFont=cmunbx,
  ItalicFont=cmunti,
  BoldItalicFont=cmunbi,
]{cmunrm}
\usepackage{polyglossia}
\setdefaultlanguage{russian}
\setotherlanguage{english}
\PolyglossiaSetup{russian}{indentfirst=true}

% Для математики
\usepackage{amssymb,amsmath}

% Для множества колонок
\usepackage{multicol}

% Для отображения алгоритмов
\usepackage[ruled,linesnumbered,lined,commentsnumbered]{algorithm2e}
\SetKw{KwAnd}{and}

% Собственные обозначения для скобок
\newcommand{\roubr}[1]{\left(#1\right)}
\newcommand{\sqbr}[1]{\left[#1\right]}
\newcommand{\cubr}[1]{\left\{#1\right\}}

% Для отображения ссылок
\usepackage{hyperref}

\begin{document}
\title{Метод Ньютона для решения систем нелинейных уравнений}
\author{Шепрут Илья}
\maketitle

\tableofcontents

\newpage

\section{Введение}

Часто в программировании возникает задача решать системы уравнений, причем это не обычные Системы Линейных Алгебраических Уравнений (СЛАУ), для которых существует несчетное число методов решения, а нелинейные системы, где аналитическое решение чаще всего не выражается. Тут на помощь приходят численные методы нахождения решения. Метод Ньютона является одним из них. Если обычный метод Ньютона решает одномерные уравнения, то в данной статье будет описан этот метод для многомерного случая, то есть когда у нас не одно уравнение, а система.

Всё будет описано для размерности $n = 2$, но это легко обобщается на более высокие размерности.

\setlength{\columnsep}{30pt}
\begin{multicols}{2}

\section{Формулировка}

Дана Система Нелинейных Уравнений (СНУ) в виде:

\begin{equation}\label{dano}
\left\{
\begin{aligned}
	&F_1(x_1,\ x_2) = 0 \\
	&F_2(x_1,\ x_2) = 0
\end{aligned}
\right.
\end{equation}

Требуется, чтобы она имела непрерывные производные $1$ порядка.

Необходимо найти такие $x_1$, $x_2$ при которых система оборачивается в нуль. Это называется решение СНУ.

\section{Обозначения}

Заменим в \eqref{dano} аргументы на вектор $\mathbf{x} = (x_1,\ x_2)$:

\begin{equation}\label{dano1}
\left\{
\begin{aligned}
	&F_1(\mathbf{x}) = 0 \\
	&F_2(\mathbf{x}) = 0
\end{aligned}
\right.
\end{equation}

Преобразуем \eqref{dano1} к одной вектор-функции $\mathbf{F}$, такой что $ \mathbf{F} : \mathbb{R}^2 \to \mathbb{R}^2 $:

$$\mathbf{F}(\mathbf{x}) = \roubr{
\begin{aligned}
	&F_1(\mathbf{x})\\
	&F_2(\mathbf{x})\\
\end{aligned}
}
$$

Тогда \eqref{dano} примет вид:

\begin{equation}\label{dano2}
\mathbf{F}(\mathbf{x}) = \mathbf{0}
\end{equation}

где $\mathbf{0}= (0,\ 0)^T$.

Под \textbf{невязкой} понимается вектор $\mathbf{F}(\mathbf{x})$.

\end{multicols}

\section{Преобразования}

\subsection{Разложение в ряд Тейлора для функции многих переменных}

Взято с \href{https://en.wikipedia.org/wiki/Taylor_series#Taylor_series_in_several_variables}{Википедии}.

Пусть дана функция $f(\mathbf{x}) : \mathbb{R}^2 \to \mathbb{R}$, $\mathbf{x} = (x_1,\ x_2)^T$.

Разложение функции $f(\mathbf{x})$ будет произведено в окрестности точки $\mathbf{a} = (a_1,\ a_2)^T$. Требуется, чтобы у функции $f$ имелись непрерывные производные до $(2+1)$-го порядка включительно по всем переменным.

Тогда разложение в ряд Тейлора имеет следующий вид:

\begin{equation}
f(\mathbf{x}) = f(\mathbf{a}) + \sum_{i = 1}^n \frac{\partial f(\mathbf{a})}{\partial x_i} (x_i - a_i) + \frac{1}{2!} \sum_{i = 1}^2\sum_{j = 1}^2 \frac{\partial f(\mathbf{a})}{\partial x_i \partial x_j} (x_i - a_i) (x_j - a_j) + R_3(\mathbf{x}) 
\end{equation}

Раскроем сумму первых двух членов предыдущего равенства:

\begin{equation}\label{taylor}
f(\mathbf{x}) = f(\mathbf{a}) + \frac{\partial f(\mathbf{a})}{\partial x_1} (x_1 - a_1) + \frac{\partial f(\mathbf{a})}{\partial x_2} (x_2 - a_2) + R_2(\mathbf{x})
\end{equation}

\begin{equation}\label{rtozero}
\text{Где } R_n(\mathbf{x}) \text{ --- остаточный член в форме Лагранжа, } R_n(\mathbf{x}) \xrightarrow{n\to \infty} 0 \text{ .}
\end{equation}

\subsection{Разложение в ряд Тейлора СНУ}

Обозначим за $\hat{\mathbf{x}}$ искомое решение, за $\mathbf{x}^{[k]}$ решение на $k$-м шаге и введем ещё обозначение смещения $\Delta\mathbf{x}^{[k]} = \hat{\mathbf{x}} - \mathbf{x}^{[k]}$.

Разложим $F_i\roubr{\mathbf{x}}$ в окрестности точки $\mathbf{x}^{[k]}$ в ряд Тейлора по формуле \eqref{taylor}:

$$ F_i\roubr{\mathbf{x}} = F_i\roubr{\mathbf{x}^{[k]}} + \frac{\partial F_i\roubr{\mathbf{x}^{[k]}}}{\partial x_1} \roubr{x_1 - x^{[k]}_1} + \frac{\partial F_i\roubr{\mathbf{x}^{[k]}}}{\partial x_2} \roubr{x_2 - x^{[k]}_2} + R_2\roubr{\mathbf{x}} $$

Подставив в это разложение точку $\hat{\mathbf{x}}$ получаем следующее:

$$\displaystyle F_i\roubr{\hat{\mathbf{x}}} = F_i\roubr{\mathbf{x}^{[k]}} + \frac{\partial F_i\roubr{\mathbf{x}^{[k]}}}{\partial x_1} \Delta x^{[k]}_1 + \frac{\partial F_i\roubr{\mathbf{x}^{[k]}}}{\partial x_2} \Delta x^{[k]}_2 + R_2\roubr{\hat{\mathbf{x}}} $$

Теперь запишем \eqref{dano2} с учетом предыдущего разложения:

$$ \left\{
\begin{aligned}
& F_1\roubr{\mathbf{x}^{[k]}} + \frac{\partial F_1\roubr{\mathbf{x}^{[k]}}}{\partial x_1} \Delta x^{[k]}_1 + \frac{\partial F_1\roubr{\mathbf{x}^{[k]}}}{\partial x_2} \Delta x^{[k]}_2 + R^{F_1}_2\roubr{\hat{\mathbf{x}}} = 0 \\
& F_2\roubr{\mathbf{x}^{[k]}} + \frac{\partial F_2\roubr{\mathbf{x}^{[k]}}}{\partial x_1} \Delta x^{[k]}_1 + \frac{\partial F_2\roubr{\mathbf{x}^{[k]}}}{\partial x_2} \Delta x^{[k]}_2 + R^{F_2}_2\roubr{\hat{\mathbf{x}}} = 0
\end{aligned}
\right.$$

Или в матричном виде:

$$
\mathbf{F}\roubr{\mathbf{x}^{[k]}} + 
\begin{pmatrix}
\displaystyle \frac{\partial F_1\roubr{\mathbf{x}^{[k]}}}{\partial x_1} & \displaystyle \frac{\partial F_1\roubr{\mathbf{x}^{[k]}}}{\partial x_2} \\ \\
\displaystyle \frac{\partial F_2\roubr{\mathbf{x}^{[k]}}}{\partial x_1} & \displaystyle \frac{\partial F_2\roubr{\mathbf{x}^{[k]}}}{\partial x_2}
\end{pmatrix} \cdot \Delta \mathbf{x}^{[k]} + \begin{pmatrix}
\displaystyle R^{F_1}_2\roubr{\hat{\mathbf{x}}} \\
\displaystyle R^{F_2}_2\roubr{\hat{\mathbf{x}}}
\end{pmatrix} = \mathbf{0}
$$

$$
\mathbf{F}\roubr{\mathbf{x}^{[k]}} + \mathbf{J}_\mathbf{F}\roubr{\mathbf{x}^{[k]}} \cdot \Delta \mathbf{x}^{[k]} + \mathbf{R}_2\roubr{\hat{\mathbf{x}}} = \mathbf{0}
$$

$$
\mathbf{J}_\mathbf{F}\roubr{\mathbf{x}^{[k]}} \cdot \Delta \mathbf{x}^{[k]} = -\mathbf{F}\roubr{\mathbf{x}^{[k]}} - \mathbf{R}_2\roubr{\hat{\mathbf{x}}}
$$

Где $\mathbf{J}_\mathbf{F}\roubr{\mathbf{x}}$ --- матрица Якоби функции $\mathbf{F}$ в точке $\mathbf{x}$.

Из этого уравнения можно найти $\Delta\mathbf{x}^{[k]}$, который прибавляется к текущему решению $\mathbf{x}^{[k]}$ чтобы найти $\hat{\mathbf{x}}$. 

Мы не не знаем как вычислять $\mathbf{R}_2\roubr{\hat{\mathbf{x}}}$, но можем им пренебречь, так как он стремится к нулю. Именно из-за этого принебрежения мы не сразу получаем точное решение, а процесс становится итеративным. Итог:

\begin{equation}\label{slau}
\mathbf{J}_\mathbf{F}\roubr{\mathbf{x}^{[k]}} \cdot \Delta \mathbf{x}^{[k]} = -\mathbf{F}\roubr{\mathbf{x}^{[k]}}
\end{equation}

Можно заметить, что это СЛАУ. Её можно легко решить известными методами.

\section{Алгоритм}

\section{Стандартный метод Ньютона}

Весь метод заключается в итерационном процессе:

\begin{equation}\label{iter0}
\mathbf{x}^{[k+1]} = \mathbf{x}^{[k]} + \Delta \mathbf{x}^{[k]}
\end{equation}

\begin{equation}\label{iter}
\mathbf{x}^{[k+1]} = \mathbf{x}^{[k]} - \roubr{\mathbf{J}_\mathbf{F}\roubr{\mathbf{x}^{[k]}}}^{-1} \mathbf{F}\roubr{\mathbf{x}^{[k]}}
\end{equation}

Далее за $k$ обозначается количество итераций; за $m$ максимальное число итераций; за $\varepsilon_1$ максимальная допустимая невязка;

\begin{algorithm}[H]
\DontPrintSemicolon
\KwIn{$\varepsilon_1$, $m$, $\mathbf{F}$, $\mathbf{x}^{[0]}$}
\KwResult{$\mathbf{x}$}
\Begin{
	$\mathbf{x} \leftarrow \mathbf{x}^{[0]}$\;
	$k \leftarrow 0$\;
	\While{$||\mathbf{F}\roubr{\mathbf{x}}|| > \varepsilon_1$ \KwAnd $k < m$}{
		$\mathbf{A} \leftarrow \mathbf{J}_\mathbf{F}\roubr{\mathbf{x}}$\;
		$\mathbf{b} \leftarrow -\mathbf{F}\roubr{\mathbf{x}}$\;
		Решить СЛАУ $\mathbf{A}\cdot \Delta\mathbf{x} = \mathbf{b}$, результат поместить в $\Delta\mathbf{x}$\;
		$\mathbf{x} \leftarrow \mathbf{x} + \Delta\mathbf{x}$\;
		$k \leftarrow k + 1$\;
	}
}
\caption{Метод Ньютона}
\end{algorithm}

Выход из итерационного процесса производится когда невязка достигает необходимой нижней границы, либо превышается максимальное число итераций.

В $||\mathbf{F}\roubr{\mathbf{x}}|| > \varepsilon_1$ невязка считается через норму, потому что так проще сравнить вектор с одним числом. Норма выбирается по вашему усмотрению.

\textit{Замечание:} данный алгоритм не зависит от размерности системы, а, следовательно, может быть применен к любой размерности исходной СНУ.

\textit{Замечание:} в алгоритме используется матрица Якоби в известной точке, что означает, что знать её аналитическое выражение не нужно, её можно вычислять при помощи численного взятия производной в конкретной точке.

\subsection{Улучшенный метод Ньютона}

Иногда может получаться такой $\Delta \mathbf{x}$, что невязка в векторе $\mathbf{x}^{[k+1]}$ будет больше, чем в $\mathbf{x}^{[k]}$, поэтому вводится коэффициент $\beta \in \sqbr{0, 1}$, который домножается на $\Delta \mathbf{x}$, причем $\beta$ подбирается такой, чтобы невязка строго уменьшалась. Тогда \eqref{iter0} будет выглядеть следующим образом:

$$
\mathbf{x}^{[k+1]} = \mathbf{x}^{[k]} + \beta \cdot \Delta \mathbf{x}^{[k]}
$$

Чтобы найти такой $\beta$, при котором невязка будет уменьшаться, используется аналог двоичного поиска: изначально $\beta = 1$, затем, пока невязка нового решения больше, чем предыдущего, $\beta$ уменьшается вдвое. 

Так же, если $\beta \to 0$, то это означает, что невязка не может быть уменьшена на текущей итерации, и это ещё один повод завершить итерационный процесс.

\begin{algorithm}[H]
\DontPrintSemicolon
\KwIn{$\varepsilon_1$, $\varepsilon_2$, $m$, $\mathbf{F}$, $\mathbf{x}^{[0]}$}
\KwResult{$\mathbf{x}$}
\Begin{
	$\mathbf{x} \leftarrow \mathbf{x}^{[0]}$\;
	$\beta \leftarrow 1$\;
	$k \leftarrow 0$\;
	\While{$||\mathbf{F}\roubr{\mathbf{x}}|| > \varepsilon_1$ \KwAnd $\beta > \varepsilon_2$ \KwAnd $k < m$}{
		$\mathbf{A} \leftarrow \mathbf{J}_\mathbf{F}\roubr{\mathbf{x}}$\;
		$\mathbf{b} \leftarrow -\mathbf{F}\roubr{\mathbf{x}}$\;
		Решить СЛАУ $\mathbf{A}\cdot \Delta \mathbf{x} = \mathbf{b}$, результат поместить в $\Delta \mathbf{x}$\;
		$\beta \leftarrow 1$\;
		\While{$||\mathbf{F}\roubr{\mathbf{x} + \beta \Delta\mathbf{x}}|| > ||\mathbf{F}\roubr{\mathbf{x}}||$ \KwAnd $\beta > \varepsilon_2$}{
			$\beta \leftarrow 0.5 \beta$\;
		}
		$\mathbf{x} \leftarrow \mathbf{x}^{[k]} + \beta\cdot \Delta \mathbf{x}$\;
		$k \leftarrow k + 1$\;
	}
}
\caption{Улучшенный Метод Ньютона}
\end{algorithm}

\subsection{Одномерный случай}

В одномерном случае \eqref{iter} преобразуется к:

$$ x^{[k+1]} = x^{[k]} - \roubr{\frac{d f\roubr{x^{[k]}}}{dx}}^{-1} f\roubr{x^{[k]}} = x^{[k]} - \frac{f\roubr{x^{[k]}}}{f'\roubr{x^{[k]}}} $$

\section{Пример}

Например, у нас имеется следующая СНУ:

$$\left\{
\begin{aligned}
	&(x-x_1)^2 + (y-y_1)^2 = (r_1 + r)^2 \\
	&(x-x_2)^2 + (y-y_2)^2 = (r_1 + r)^2 \\
	&\cfrac{|ax + by + c|}{\sqrt{a^2 + b^2}} = r
\end{aligned}
\right.
$$

Решением этой СНУ является окружность с центром в точке $(x,\ y)$ и радиусом $r$, которая касается внешним образом окружностей $(x_1,\ y_1,\ r_1)$, $(x_2,\ y_2,\ r_2)$ и прямой $ax + by + c = 0$.

Для этой системы получим:

$$
\mathbf{F} = \begin{pmatrix}
	(x-x_1)^2 + (y-y_1)^2 - (r_1 + r)^2 \\
	(x-x_2)^2 + (y-y_2)^2 - (r_1 + r)^2 \\
	\cfrac{|ax + by + c|}{\sqrt{a^2 + b^2}} - r
\end{pmatrix},\
\mathbf{J}_\mathbf{F} = \begin{pmatrix}
	2(x-x_1) & 2(y-y_1) & -2(r_1 + r) \\
	2(x-x_2) & 2(y-y_2) & -2(r_2 + r) \\
	\cfrac{|a|}{\sqrt{a^2 + b^2}} & \cfrac{|b|}{\sqrt{a^2 + b^2}} & -1
\end{pmatrix}
$$

Далее остается только применить алгоритм.

\section{Когда размерность СНУ не соответствует размерности решения}

Пусть дана СНУ:

$$\left\{
\begin{aligned}
	&F_1(x_1,\ x_2,\ \dots,\ x_n) = 0 \\
	&F_2(x_1,\ x_2,\ \dots,\ x_n) = 0 \\
	&\dots \\
	&F_m(x_1,\ x_2,\ \dots,\ x_n) = 0
\end{aligned}
\right.
$$

Вышеописанный алгоритм работает только когда $m=n$, но бывают так же случаи когда $m\neq n$. Если попробовать применить алгоритм к такой СНУ, то можно заметить, что проблемы с ней возникают только при вычислении решения СЛАУ. И следующие методы как раз будут давать методы решения СЛАУ конкретно для этой задачи.

И в алгоритме возникают лишь небольшие изменения:

\subsection{Расширенный метод Ньютона для $m \neq n$}

\begin{algorithm}[H]
\DontPrintSemicolon
\KwIn{$\varepsilon_1$, $\varepsilon_2$, $m$, $\mathbf{F}$, $\mathbf{x}^{[0]}$}
\KwResult{$\mathbf{x}$}
\Begin{
	$\mathbf{x} \leftarrow \mathbf{x}^{[0]}$\;
	$\beta \leftarrow 1$\;
	$k \leftarrow 0$\;
	\While{$||\mathbf{F}\roubr{\mathbf{x}}|| > \varepsilon_1$ \KwAnd $\beta > \varepsilon_2$ \KwAnd $k < m$}{
		$\mathbf{A} \leftarrow \mathbf{J}_\mathbf{F}\roubr{\mathbf{x}}$\;
		$\mathbf{b} \leftarrow -\mathbf{F}\roubr{\mathbf{x}}$\;
		$\Delta \mathbf{x} \leftarrow \mathbb{S}\roubr{\mathbf{A}, \mathbf{b}, \mathbf{F}, \mathbf{x}}$\;
		\While{$||\mathbf{F}\roubr{\mathbf{x} + \beta \Delta\mathbf{x}}|| > ||\mathbf{F}\roubr{\mathbf{x}}||$ \KwAnd $\beta > \varepsilon_2$}{
			$\beta \leftarrow 0.5 \beta$\;
		}
		$\mathbf{x} \leftarrow \mathbf{x}^{[k]} + \beta\cdot \Delta \mathbf{x}$\;
		$k \leftarrow k + 1$\;
	}
}
\caption{Расширенный Метод Ньютона для $m \neq n$}
\end{algorithm}

Где $\mathbb{S}$ --- функция, получающая текущую СЛАУ функцию вычисления и текущее решение, возвращающая вектор смещения $\Delta\mathbf{x}$. Данная функция <<решает>> эту СЛАУ некоторым методом. Этим методам и будет посвящена следующие главы.

Главная цель функции $\mathbb{S}$ --- по всем имеющимся данным найти такой подходящий вектор смещения, чтобы решение двигалось в сторону уменьшения невязки.

В случае, когда $m = n$, $\mathbb{S}$ --- просто функция, решающая обычную СЛАУ.

\subsection{$m < n$}

Это означает, что решений, где исходная СНУ оборачивается в ноль, множество.

Так же это означает, что не хватает уравнений, для того, чтобы построить полный вектор смещения $\Delta\mathbf{x}$ при решении СЛАУ. Поэтому делается так, чтобы в итоге некоторые компоненты $\Delta\mathbf{x}$ были равны нулю, предполагается что по этим компонентам уже найдено достаточно хорошее решение, и искать для них смещения не нужно. 

Какие именно компоненты занулять --- выбирается таким образом, чтобы подтверждалось вышеописанное предположение. В данном случае они выбирается по значениям частных производных, то есть для каждой компоненты под номером $j$ находится число $y_j = \max_i \left|\frac{\partial F_i(\mathbf{x})}{\partial x_j}\right|$, и зануляются те $(n-m)$ компонент, для которых $y_j$ минимально.

Далее можно просто исключить соответствующие строки из матрицы Якоби и компоненты из вектора $\mathbf{b}$.

Именно в этих действиях и заключается функция $\mathbb{S}$ для этого метода.

\subsection{$m > n$}	

Это означает, что решений может не быть, в данном случае метод Ньютона находит точку с минимальной невязкой.

Так же это означает, что уравнений слишком много, чтобы найти вектор смещения $\Delta\mathbf{x}$, поэтому придумываются методы, чтобы либо исключить какие-то уравнения, либо скомбинировать их каким-то образом. Но нельзя сделать эти преобразования один раз. На каждой итерации придется делать это заного.

\subsubsection{Метод исключения}

Создается новая СНУ, состоящая только из тех $n$ уравнений, для которых $|F_i(\mathbf{x})|$ максимально.

Далее для полученной СНУ заного считается матрица Якоби, вектор $\mathbf{b}$, и уже по новым данным получается СЛАУ корректного размера, по которой находится $\Delta \mathbf{x}$.

\textit{Обратите внимание, что} можно получить матрицу Якоби нового уравнения и вектор $\mathbf{b}$ лишь исключив нужные строки.

\subsubsection{Метод свертки}

Создается новая СНУ, которая состоит из $(n-1)$ уравнений исходной СНУ, для которых $|F_i(\mathbf{x})|$ максимально, все оставшиеся $(n-m-1)$ уравнений комбинируются: складывается сумма их квадратов.

Далее для полученной СНУ заного считается матрица Якоби, вектор $\mathbf{b}$, и уже по новым данным получается СЛАУ корректного размера, по которой находится $\Delta \mathbf{x}$.

\textit{Обратите внимание, что} можно получить матрицу Якоби нового уравнения и вектор $\mathbf{b}$, сложив необходимые строки матрицы Якоби, помноженные на $2\mathbf{b}$, а в векторе $\mathbf{b}$ сложить необходимые строки в квадрате. 

В матрице Якоби надо складывать строки именно с такими действиями, потому что матрица Якоби состоит из производных, и данные действия можно получить, взяв производную суммы квадратов уравнений.

\subsubsection{Процедура симметризации}

Вместо исходной системы должна решаться система:

$$\roubr{\mathbf{J}_\mathbf{F}\roubr{\mathbf{x}^{[k]}}}^T \cdot \mathbf{J}_\mathbf{F}\roubr{\mathbf{x}^{[k]}} \cdot \Delta \mathbf{x} = \roubr{\mathbf{J}_\mathbf{F}\roubr{\mathbf{x}^{[k]}}}^T \cdot \mathbf{F}\roubr{\mathbf{x}^{[k]}} $$

\end{document}